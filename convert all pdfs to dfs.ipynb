{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all pdfs to pandas dataframes\n",
    "Tested under Python 3.7.<br>\n",
    "This notebook converts all abstract pdfs in one directory into one dataframe that has one entry for each abstract, and rows as defined in an auxiliary csv (e.g., *abstract_title*, *abstract_id*, *submitted_by*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define directories, settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with pdfs\n",
    "path = r''\n",
    "\n",
    "# columns in dataframe:\n",
    "cols = ['abstract_title', 'abstract_id', 'submitted_by', 'source', 'overview', 'summary', 'implications']\n",
    "\n",
    "# path to csv that holds the tag words that designate the beginning and end of a section \n",
    "csv_cols_completed = r'cols.csv'\n",
    "\n",
    "# number of characters printed for each abstract, for debugging\n",
    "print_chars = 0\n",
    "\n",
    "# drop rows that have empty cells (e.g., no summary)\n",
    "# (rows that don't have an abstract_id will always be dropped)\n",
    "drop_rows = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import sys, getopt\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    import time\n",
    "    return time.strftime('_%Y%m%d_%H%M%S')\n",
    "\n",
    "def open_pdf(fname):\n",
    "    \"\"\"\n",
    "    opens fname, returns pdf object\n",
    "    also works with encrypted pdf files, at least some of them\n",
    "    \"\"\"\n",
    "    import PyPDF2\n",
    "    pdf = PyPDF2.PdfFileReader(fname, 'rb')\n",
    "    if pdf.isEncrypted:\n",
    "        pdf.decrypt(\"\")\n",
    "    return pdf\n",
    "\n",
    "def remove_specialchars(str, list):\n",
    "    for item in list:\n",
    "        str = str.replace(item, ' ')\n",
    "    return str\n",
    "\n",
    "def page2txt(pdf, n):\n",
    "    page = pdf.getPage(n)\n",
    "#     print(type(page.extractText()))\n",
    "#     print(type(page.extractText().encode('utf-8')))\n",
    "#     return page.extractText().encode('utf-8')\n",
    "    txt = page.extractText()\n",
    "    specialcharlist = ['\\n']\n",
    "    return remove_specialchars(txt, specialcharlist)    \n",
    "\n",
    "def txt_contains_abstract(txt, df_cols):\n",
    "    \"\"\"\n",
    "    checks if txt contains abstract\n",
    "    must have keywords to be considered abstract (\"summary\", \"overview\" etc.)\n",
    "    input:\n",
    "        txt: txt string\n",
    "        df_cols: dataframe with strings that mark the beginning of a section\n",
    "    output:\n",
    "        True if txt contains abstract, i.e. > 80% of the marker strings\n",
    "        False otherwise\n",
    "    \"\"\"\n",
    "    return np.average(np.array(df_cols.startstring.apply(lambda x: len(txt.split(x))>1).astype(float))) > .8\n",
    "\n",
    "def get_section(txt, df_cols, section_name):\n",
    "    \"\"\"\n",
    "    extracts section from txt string\n",
    "     input:\n",
    "        txt: txt string\n",
    "        df_cols: dataframe with strings that mark the beginning of a section\n",
    "        section_name: name of section to be extracted\n",
    "    output:\n",
    "        section\n",
    "    \"\"\"\n",
    "    startstring = df_cols.loc[df_cols.category == section_name].startstring.values[0]\n",
    "    endstring = df_cols.loc[df_cols.category == section_name].endstring.values[0]\n",
    "    endstring_alt = df_cols.loc[df_cols.category == section_name].endstring_alt.values[0]\n",
    "#     print 'startstring, endstring, endstring_alt: ', startstring, endstring, endstring_alt\n",
    "    sections = txt.split(startstring)\n",
    "    if len(sections) == 1:\n",
    "        print('Could not find ', startstring, ' in ', txt[:print_chars], '...')\n",
    "        return ''\n",
    "    sections = sections[1:]\n",
    "    for i, section in enumerate(sections):\n",
    "        sections[i] = section.split(endstring)[0].split(endstring_alt)[0].rstrip().lstrip()\n",
    "    if len(sections) != 1:\n",
    "        print('Attention, ', section_name, ' appeared > 1x in ', txt[:print_chars], '...')\n",
    "    return sections[0]\n",
    "\n",
    "def txt2row(txt, df_cols, cols):\n",
    "    \"\"\"\n",
    "    turns string into one dataframe row with columns cols\n",
    "    input:\n",
    "        txt: string\n",
    "        df_cols: dataframe with strings that mark the beginning of a section\n",
    "        cols: np.array with names of columns\n",
    "    output:\n",
    "        one row as dict with col names as indices\n",
    "    \"\"\"\n",
    "    row = {}\n",
    "    for col in cols:\n",
    "        row[col] = get_section(txt, df_cols, col)\n",
    "    return row\n",
    "    \n",
    "def drop_rows_with_empty_cells(df):\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.dropna(axis=0, how='any', inplace = True)\n",
    "    return df\n",
    "\n",
    "def make_index(a, prefix):\n",
    "    a2 = np.zeros_like(a, dtype=object)\n",
    "    for i in range(len(a)):\n",
    "        a2[i] = prefix+str(a[i]).zfill(3)\n",
    "    return a2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert each pdf to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(path, '*.pdf'))\n",
    "df_cols = pd.read_csv(csv_cols_completed)\n",
    "\n",
    "for f in files:\n",
    "    print(f)\n",
    "    pdf = open_pdf(f)\n",
    "    n_pages = pdf.getNumPages()\n",
    "    df_abstracts = pd.DataFrame(columns=cols)\n",
    "    for n in range(n_pages):\n",
    "        print('page ', str(n))\n",
    "        txt = page2txt(pdf, n)\n",
    "        print(txt[:print_chars], '....')\n",
    "        if not txt_contains_abstract(txt, df_cols):\n",
    "            print('Page does not contain abstract.')\n",
    "        else:\n",
    "            print('Page contains abstract.')\n",
    "            row = txt2row(txt, df_cols, cols)\n",
    "#             row['index'] = row['abstract_id']\n",
    "            print(row['abstract_id'])\n",
    "            df_abstracts = df_abstracts.append(row, ignore_index=True)\n",
    "        print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    print('number of rows in df: ', len(df_abstracts))\n",
    "    if drop_rows: \n",
    "        df_abstracts = drop_rows_with_empty_cells(df_abstracts)\n",
    "    df_abstracts = df_abstracts[df_abstracts['abstract_id'] != ''] # remove rows with empty abstract_id field\n",
    "    print('number of rows in df: ', len(df_abstracts))\n",
    "    df_abstracts = df_abstracts.set_index('abstract_id')\n",
    "    display(df_abstracts)\n",
    "    df_abstracts.to_pickle(f.replace('.pdf', '.df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot contributions from each contributor (\"submitted by\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = np.unique(df_abstracts.submitted_by.values)\n",
    "author_counts = np.zeros(len(authors))\n",
    "for i, author in enumerate(authors):\n",
    "    author_counts[i] = np.sum(df_abstracts.submitted_by == author)\n",
    "s = np.argsort(author_counts)[::-1]\n",
    "author_counts = author_counts[s]\n",
    "authors = authors[s]\n",
    "xvalues = np.arange(len(authors))\n",
    "plt.plot(xvalues, author_counts, 'xr')\n",
    "plt.xticks(xvalues, authors, rotation=90)\n",
    "plt.savefig(r'your path here \\submitted_by_plot'+timestamp()+'.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine dataframes into one big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = glob.glob(os.path.join(path, '*.df'))\n",
    "df_all = pd.read_pickle(dfs[0])\n",
    "for dfi in dfs[1:]:\n",
    "    print('Now appending ', dfi)\n",
    "    df = pd.read_pickle(dfi)\n",
    "    print(len(df))\n",
    "    df_all = df_all.append(df)\n",
    "    print(len(df_all))\n",
    "df_all.to_pickle(os.path.join(path, 'combined', 'all_abstracts'+timestamp()+'.df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = glob.glob(os.path.join(path, 'combined', 'all_abstracts*.df'))[-1]\n",
    "print(df_all)\n",
    "df_all = pd.read_pickle(df_all)\n",
    "print(len(df_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scansmeeting_py37",
   "language": "python",
   "name": "scansmeeting_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
